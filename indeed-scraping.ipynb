{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "indeed-scraping.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP/QjeNFDygdX94hXMrnhCH"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87QWvvlxmO1o"
      },
      "source": [
        "Reference: https://towardsdatascience.com/web-scraping-indeed-com-e5591790736d\n",
        "\n",
        "Reference:\n",
        "https://github.com/rowandl/portfolio/blob/master/Webscraping%20Indeed.com/Webscraping%20Indeed.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "059xIR_a-Npr"
      },
      "source": [
        "#!pip install pandas\n",
        "#!pip install bs4\n",
        "#!pip install matplotlib\n",
        "#!pip install lxml"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oPMabF7_WtH"
      },
      "source": [
        "import pandas as pd\n",
        "import urllib\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "import time\n",
        "\n",
        "from IPython.display import HTML"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXG3nDTOqrxA",
        "outputId": "55386940-a382-4963-cfac-46d1cede32de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# top 10 canada cities\n",
        "cities = ['Toronto', 'Montreal', 'Vancouver', 'Calgary', 'Edmonton', 'Ottawa', 'Winnipeg', 'Quebec+City', 'Hamilton', 'Kitchener']\n",
        "#cities = ['Toronto']\n",
        "\n",
        "# Set this to a high-value to generate more results. High value might get block by website\n",
        "max_results_per_city = 100\n",
        "#max_results_per_city = 10\n",
        "\n",
        "total_count = len(cities) * max_results_per_city\n",
        "city_count = 0\n",
        "job_count = 0\n",
        "\n",
        "#making a dataframe which collects all the information from my webscraping\n",
        "#https://www.indeed.ca/jobs?q=data+scientist+%2420%2C000&l=Toronto&start=0\n",
        "url_template = \"https://www.indeed.ca/jobs?q=data+scientist+%2420%2C000&l={}&start={}\"\n",
        "base_url = \"https://ca.indeed.com\"\n",
        "\n",
        "df = pd.DataFrame(columns=[\"location\", 'company', 'job_title', 'salary', 'job_description','job_url'])\n",
        "\n",
        "for city in cities:\n",
        "    for start in range(0, max_results_per_city, 10):\n",
        "        url = url_template.format(city,start)\n",
        "        html = urllib.request.urlopen(url).read()\n",
        "        soup = BeautifulSoup(html, \"html.parser\")\n",
        "        for b in soup.find_all('div', attrs = {'class': 'result'}):\n",
        "            try:\n",
        "                location = b.find('div', attrs = {'class': 'location'}).text\n",
        "            except:\n",
        "                try:\n",
        "                    location = b.find('span', attrs = {'class': 'location'}).text\n",
        "                except:\n",
        "                    location = 'NA'\n",
        "\n",
        "            job_title = b.find('a', attrs = {'data-tn-element':'jobTitle'}).text\n",
        "            job_title = job_title.replace(\"\\n\",\"\")\n",
        "            \n",
        "            job_url = b.find('a', attrs = {'data-tn-element':'jobTitle'}).get('href')\n",
        "\n",
        "            try:\n",
        "                company = b.find('span', attrs = {'class':'company'}).text\n",
        "                company = company.replace(\"\\n\",\"\")\n",
        "            except:\n",
        "                company = 'NA'\n",
        "            try:\n",
        "                salary = b.find('td', attrs = {'class' : 'snip'}).find('nobr').text  \n",
        "            except:\n",
        "                salary = 'NA'\n",
        "            \n",
        "            time.sleep(1) # to prevent web blocking\n",
        "\n",
        "            url_job = 'https://ca.indeed.com' + job_url\n",
        "            html_job = urllib.request.urlopen(url_job).read()\n",
        "            soup_job = BeautifulSoup(html_job, \"html.parser\")\n",
        "\n",
        "            try:\n",
        "                description = soup_job.find('div', attrs = {'id': 'jobDescriptionText'}).text\n",
        "            except:\n",
        "                description = 'NA'\n",
        "\n",
        "            done = int((city_count*100+job_count)/total_count*100)\n",
        "\n",
        "            print(\"%d%%: %s: %s > %s > %s\" % (done, city, location, company, job_title))\n",
        "\n",
        "            if (description != 'NA'):\n",
        "                df = df.append({\"location\":location,\"company\":company, \"job_title\": job_title, \"salary\": salary, \"job_description\": description, \"job_url\": url_job}, ignore_index=True)\n",
        "            \n",
        "            #time.sleep(1) # to prevent web blocking\n",
        "            job_count += 1\n",
        "\n",
        "    city_count += 1\n",
        "    job_count = 0\n",
        "   \n",
        "df.drop_duplicates(inplace=True)\n",
        "df.company.replace(inplace=True,regex=True,to_replace=\"\\n\",value=\"\")\n",
        "df.job_title.replace(inplace=True,regex=True,to_replace=\"\\n\",value=\"\")\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0%: Toronto: Greater Toronto Area, ON > fgf brands > Data Scientist Co-op ( 4 or 8 Month Winter Placement)\n",
            "0%: Toronto: North York, ON > Poros Career > Data Analyst\n",
            "0%: Toronto: Toronto, ON > Indigo Park > Data Scientist\n",
            "0%: Toronto: Toronto, ON > Sunnyfuture Group > Data Analyst/Financial Analyst\n",
            "0%: Toronto: Toronto, ON > TELUS > Data Scientist\n",
            "0%: Toronto: Toronto, ON > QuadReal > Intern, Data Scientist\n",
            "0%: Toronto: Toronto, ON > Overbond > Data Scientist\n",
            "0%: Toronto: Toronto, ON > Equifax > Data Scientist - Client Success\n",
            "0%: Toronto: Toronto, ON > Gannett > Data Scientist\n",
            "0%: Toronto: Toronto, ON > TELUS > Data Scientist - TELUS Digital\n",
            "1%: Toronto: Mississauga, ON > Compass Digital Labs > Data Scientist (Decision Science)\n",
            "1%: Toronto: Mississauga, ON > Hatch > Data Scientist\n",
            "1%: Toronto: Toronto, ON > float simple > Lead Data Scientist - BI Analytics\n",
            "1%: Toronto: Toronto, ON > 7D Surgical > Data Analyst Intern\n",
            "1%: Toronto: Mississauga, ON > Traffic Tech Inc. > Data Scientist\n",
            "1%: Toronto: Toronto, ON > TripStack > Data Scientist\n",
            "1%: Toronto: Toronto, ON > Zynga > Data Scientist II\n",
            "1%: Toronto: Toronto, ON > Arteria AI > Data Scientist\n",
            "1%: Toronto: Toronto, ON > OMERS Capital Markets > Investment Data Scientist, Global Diversified Program\n",
            "1%: Toronto: Toronto, ON > Just Energy > Data Scientist\n",
            "2%: Toronto: Toronto, ON > Wish > Data Scientist\n",
            "2%: Toronto: Etobicoke, ON > Relay Medical Corp. > Data Science / Machine Vision Intern\n",
            "2%: Toronto: Toronto, ON > QUESTRADE INC > Data Scientist, Advanced Analytics\n",
            "2%: Toronto: North York, ON > Canadian College of Business, Science and Technolo... > Big Data (Spark, R Programming, Machine Learning)\n",
            "2%: Toronto: Toronto, ON > Veeva Systems > Data Scientist (Remote)\n",
            "2%: Toronto: Toronto, ON > Points International > Data Scientist\n",
            "2%: Toronto: Toronto, ON > Southern Graphics Systems, Canada Co. > Data Scientist\n",
            "2%: Toronto: Toronto, ON > Exiger > Tech - Data Analyst\n",
            "2%: Toronto: Toronto, ON > Restaurant Brands International > Data Scientist, People Analytics\n",
            "2%: Toronto: Toronto, ON > Pinterest > Machine Learning Engineer, Shopping Content Mining\n",
            "3%: Toronto: Toronto, ON > Overbond > Data Scientist\n",
            "3%: Toronto: Mississauga, ON > Compass Digital Labs > Data Scientist (Decision Science)\n",
            "3%: Toronto: Toronto, ON > 7D Surgical > Data Analyst Intern\n",
            "3%: Toronto: Toronto, ON > Gannett > Data Scientist\n",
            "3%: Toronto: Toronto, ON > Capgemini > Data Scientist Consultant - Toronto\n",
            "3%: Toronto: Toronto, ON > Exiger > Junior NLP Data Researcher\n",
            "3%: Toronto: Toronto, ON > TripStack > Data Scientist\n",
            "3%: Toronto: Toronto, ON > Johnson & Johnson Family of Companies > Manager, Data and Analytics Centre\n",
            "3%: Toronto: Etobicoke, ON > Moneris Solutions Corporation > Manager, Data Science\n",
            "3%: Toronto: Toronto, ON > shopkick > Data Scientist\n",
            "4%: Toronto: Toronto, ON > fabriik > Head of Analytics\n",
            "4%: Toronto: Toronto, ON > Wish > Data Scientist\n",
            "4%: Toronto: Toronto, ON > Goldman Sachs > Machine Learning Engineer - Core Engineering\n",
            "4%: Toronto: Toronto, ON > Labatt Breweries of Canada > Sr. Data Scientist\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bq5IAtnTCBI"
      },
      "source": [
        "from datetime import datetime\n",
        "\n",
        "# sending it to csvs to save the data\n",
        "now = datetime.now()\n",
        "dt_string = now.strftime(\"%y%m%d%H%M\")\n",
        "filename = \"Indeed_\" + dt_string + \".csv\"\n",
        "df.to_csv(filename , sep=',', encoding='utf-8')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mozvq2p9S_pC"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cp filename /content/gdrive/My\\ Drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juNz17X0TGXH"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(filename)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}