{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "webscrapping-1st-try.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPjA8ib25ngwzXkCbffu+2+"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87QWvvlxmO1o"
      },
      "source": [
        "Reference: https://towardsdatascience.com/web-scraping-indeed-com-e5591790736d\n",
        "\n",
        "Reference:\n",
        "https://github.com/rowandl/portfolio/blob/master/Webscraping%20Indeed.com/Webscraping%20Indeed.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "059xIR_a-Npr",
        "outputId": "6e4b3954-da5a-4f35-9329-56de4601ea96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#!pip install pandas\n",
        "#!pip install bs4\n",
        "#!pip install matplotlib\n",
        "#!pip install lxml"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.1.4)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.18.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.6/dist-packages (0.0.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from bs4) (4.6.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.18.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (4.2.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oPMabF7_WtH"
      },
      "source": [
        "import pandas as pd\n",
        "import urllib\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "import time\n",
        "\n",
        "from IPython.display import HTML"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXG3nDTOqrxA",
        "outputId": "01f16042-f372-4b68-8e3e-ed809a6484cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# top 10 canada cities\n",
        "cities = ['Toronto', 'Montreal', 'Vancouver', 'Calgary', 'Edmonton', 'Ottawa', 'Winnipeg', 'Quebec+City', 'Hamilton', 'Kitchener']\n",
        "#cities = ['Toronto']\n",
        "\n",
        "# Set this to a high-value to generate more results. High value might get block by website\n",
        "max_results_per_city = 100\n",
        "#max_results_per_city = 10\n",
        "\n",
        "#making a dataframe which collects all the information from my webscraping\n",
        "#https://www.indeed.ca/jobs?q=data+scientist+%2420%2C000&l=Toronto&start=0\n",
        "url_template = \"https://www.indeed.ca/jobs?q=data+scientist+%2420%2C000&l={}&start={}\"\n",
        "base_url = \"https://ca.indeed.com\"\n",
        "\n",
        "df = pd.DataFrame(columns=[\"location\", 'company', 'job_title', 'salary', 'job_description','job_url'])\n",
        "\n",
        "for city in cities:\n",
        "    for start in range(0, max_results_per_city, 10):\n",
        "        url = url_template.format(city,start)\n",
        "        html = urllib.request.urlopen(url).read()\n",
        "        soup = BeautifulSoup(html, \"html.parser\")\n",
        "        for b in soup.find_all('div', attrs = {'class': 'result'}):\n",
        "            try:\n",
        "                location = b.find('div', attrs = {'class': 'location'}).text\n",
        "            except:\n",
        "                try:\n",
        "                    location = b.find('span', attrs = {'class': 'location'}).text\n",
        "                except:\n",
        "                    location = 'NA'\n",
        "\n",
        "            job_title = b.find('a', attrs = {'data-tn-element':'jobTitle'}).text\n",
        "            job_title = job_title.replace(\"\\n\",\"\")\n",
        "            \n",
        "            job_url = b.find('a', attrs = {'data-tn-element':'jobTitle'}).get('href')\n",
        "\n",
        "            try:\n",
        "                company = b.find('span', attrs = {'class':'company'}).text\n",
        "                company = company.replace(\"\\n\",\"\")\n",
        "            except:\n",
        "                company = 'NA'\n",
        "            try:\n",
        "                salary = b.find('td', attrs = {'class' : 'snip'}).find('nobr').text  \n",
        "            except:\n",
        "                salary = 'NA'\n",
        "            \n",
        "            time.sleep(2) # to prevent web blocking\n",
        "\n",
        "            url_job = 'https://ca.indeed.com' + job_url\n",
        "            html_job = urllib.request.urlopen(url_job).read()\n",
        "            soup_job = BeautifulSoup(html_job, \"html.parser\")\n",
        "\n",
        "            try:\n",
        "                description = soup_job.find('div', attrs = {'id': 'jobDescriptionText'}).text\n",
        "            except:\n",
        "                description = 'NA'\n",
        "            \n",
        "            print(\"%s: %s > %s > %s\" % (city, location, company, job_title))\n",
        "\n",
        "            if (description != 'NA'):\n",
        "                df = df.append({\"location\":location,\"company\":company, \"job_title\": job_title, \"salary\": salary, \"job_description\": description, \"job_url\": url_job}, ignore_index=True)\n",
        "            \n",
        "            time.sleep(3) # to prevent web blocking\n",
        "   \n",
        "df.drop_duplicates(inplace=True)\n",
        "df.company.replace(inplace=True,regex=True,to_replace=\"\\n\",value=\"\")\n",
        "df.job_title.replace(inplace=True,regex=True,to_replace=\"\\n\",value=\"\")\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Toronto: Etobicoke, ON > Relay Medical Corp. > Data Science / Machine Vision Intern\n",
            "Toronto: Greater Toronto Area, ON > fgf brands > Data Scientist Co-op ( 4 or 8 Month Winter Placement)\n",
            "Toronto: Toronto, ON > Indigo Park > Data Scientist\n",
            "Toronto: Toronto, ON > QuadReal > Intern, Data Scientist\n",
            "Toronto: Toronto, ON > TELUS > Data Scientist\n",
            "Toronto: North York, ON > Poros Career > Data Analyst\n",
            "Toronto: Toronto, ON > Equifax > Data Scientist - Client Success\n",
            "Toronto: Toronto, ON > Overbond > Data Scientist\n",
            "Toronto: Toronto, ON > TELUS > Data Scientist - TELUS Digital\n",
            "Toronto: Toronto, ON > Sunnyfuture Group > Data Analyst/Financial Analyst\n",
            "Toronto: Toronto, ON > float simple > Lead Data Scientist - BI Analytics\n",
            "Toronto: Mississauga, ON > Compass Digital Labs > Data Scientist (Decision Science)\n",
            "Toronto: Mississauga, ON > Hatch > Data Scientist\n",
            "Toronto: Toronto, ON > TripStack > Data Scientist\n",
            "Toronto: Toronto, ON > Zynga > Data Scientist II\n",
            "Toronto: Toronto, ON > Overbond > Data Scientist\n",
            "Toronto: Toronto, ON > Prepr > Machine Learning-Part-time Fall Internship\n",
            "Toronto: Mississauga, ON > Compass Digital Labs > Data Scientist (Decision Science)\n",
            "Toronto: Toronto, ON > OMERS Capital Markets > Investment Data Scientist, Global Diversified Program\n",
            "Toronto: Toronto, ON > Exiger > Junior NLP Data Researcher\n",
            "Toronto: Toronto, ON > Veeva Systems > Data Scientist (Remote)\n",
            "Toronto: Toronto, ON > Capgemini > Data Scientist Consultant - Toronto\n",
            "Toronto: Toronto, ON > Accenture > Data & Analytics Strategy Manager\n",
            "Toronto: Toronto, ON > Gannett > Data Scientist\n",
            "Toronto: Toronto, ON > Arteria AI > Data Scientist\n",
            "Toronto: Markham, ON > IBM > Data Scientist Intern (4 months)\n",
            "Toronto: Toronto, ON > Restaurant Brands International > Data Scientist, People Analytics\n",
            "Toronto: Toronto, ON > Southern Graphics Systems, Canada Co. > Data Scientist\n",
            "Toronto: North York, ON > Canadian College of Business, Science and Technolo... > Big Data (Spark, R Programming, Machine Learning)\n",
            "Toronto: Toronto, ON > OMERS > Senior Data Analyst, Global Investments\n",
            "Toronto: Toronto, ON > Bell Canada > Senior Manager, Data Science\n",
            "Toronto: Toronto, ON > Spin Master Ltd > Senior Manager, Data Science\n",
            "Toronto: Toronto, ON > Accenture > Data & Analytics Strategy Manager\n",
            "Toronto: Toronto, ON > Gannett > Data Scientist\n",
            "Toronto: Toronto, ON > Arteria AI > Data Scientist\n",
            "Toronto: Markham, ON > IBM > Data Scientist Intern (4 months)\n",
            "Toronto: Toronto, ON > Restaurant Brands International > Data Scientist, People Analytics\n",
            "Toronto: Toronto, ON > Southern Graphics Systems, Canada Co. > Data Scientist\n",
            "Toronto: North York, ON > Canadian College of Business, Science and Technolo... > Big Data (Spark, R Programming, Machine Learning)\n",
            "Toronto: Toronto, ON > OMERS > Senior Data Analyst, Global Investments\n",
            "Toronto: Toronto, ON > Coursera > Senior Data Scientist, Machine Learning\n",
            "Toronto: Toronto, ON > Vanguard > Principal Data Scientist\n",
            "Toronto: Etobicoke, ON > Relay Medical Corp. > Data Science / Machine Vision Intern\n",
            "Toronto: Toronto, ON > BFS Capital > Lead Data Scientist – BI Analytics\n",
            "Toronto: Toronto, ON > Vanguard > Principal Data Scientist\n",
            "Toronto: Toronto, ON > ThoughtStorm > Data Scientist/Analyst and Fraud Detection\n",
            "Toronto: Etobicoke, ON > Moneris Solutions Corporation > Manager, Data Science\n",
            "Toronto: Toronto, ON > Replicant > Senior Machine Learning Engineer\n",
            "Toronto: Toronto, ON > Loblaw Digital > Senior Data Scientist\n",
            "Toronto: Toronto, ON > shopkick > Data Scientist\n",
            "Toronto: Toronto, ON > Labatt Breweries of Canada > Sr. Data Scientist\n",
            "Toronto: Toronto, ON > NorthOne > Data Scientist\n",
            "Toronto: Toronto, ON > Kinaxis > Data Scientist\n",
            "Toronto: Toronto, ON > nugget.ai > Senior Data Scientist\n",
            "Toronto: Toronto, ON > Dean Group > Machine Learning Engineer\n",
            "Toronto: Toronto, ON > Vector Institute > Director, Health AI Implementation\n",
            "Toronto: Toronto, ON > Goldman Sachs > Machine Learning Engineer - Core Engineering\n",
            "Toronto: Markham, ON > Scarsin > Data Scientist/Time Series\n",
            "Toronto: Toronto, ON > BMO Financial Group > Senior Data Scientist\n",
            "Toronto: Etobicoke, ON > Moneris Solutions Corporation > Manager, Data Science\n",
            "Toronto: Toronto, ON > Southern Graphics Systems, Canada Co. > Intern - Data Science\n",
            "Toronto: Toronto, ON > nugget.ai > Senior Data Scientist\n",
            "Toronto: Toronto, ON > Goldman Sachs > Machine Learning Engineer - Core Engineering\n",
            "Toronto: Toronto, ON > Bell Canada > Project Manager, Data Science\n",
            "Toronto: Toronto, ON > Coursera > Senior Data Scientist, Machine Learning\n",
            "Toronto: Toronto, ON > fabriik > Head of Analytics\n",
            "Toronto: Toronto, ON > Johnson & Johnson Family of Companies > Manager, Data and Analytics Centre\n",
            "Toronto: Toronto, ON > Achievers > Data Scientist\n",
            "Toronto: Toronto, ON > Lighthouse Labs > Remote PT Data Science Mentor\n",
            "Toronto: Toronto, ON > Xanadu Quantum Technologies Inc. > Machine Learning/Data Engineer\n",
            "Toronto: Toronto, ON > nugget.ai > Data Scientist\n",
            "Toronto: Toronto, ON > MindBeacon > Data Analyst - Senior level\n",
            "Toronto: Toronto, ON > TKEES > Sr. Data Analyst\n",
            "Toronto: Toronto, ON > Adante Consulting > BI Analyst\n",
            "Toronto: Toronto, ON > The Globe and Mail > SENIOR DATA SCIENTIST\n",
            "Toronto: Mississauga, ON > SOTI Inc. > Senior Data Scientist\n",
            "Toronto: Toronto, ON > Cash App > Deep Learning Engineer (Dessa), Cash App\n",
            "Toronto: Mississauga, ON > Citi > Data Science Senior Manager\n",
            "Toronto: Toronto, ON > Kinaxis > Data Scientist\n",
            "Toronto: Toronto, ON > TKEES > Sr. Data Analyst\n",
            "Toronto: Toronto, ON > IESO > Lead Data Scientist\n",
            "Toronto: Toronto, ON > Loblaw Digital > Senior Data Scientist\n",
            "Toronto: Toronto, ON > BMO Financial Group > Senior Data Scientist\n",
            "Toronto: Toronto, ON > CI Investments Inc > Data Scientist\n",
            "Toronto: Toronto, ON > Dean Group > Machine Learning Engineer\n",
            "Toronto: Toronto, ON > Capgemini > Data Science Manager - Toronto\n",
            "Toronto: Toronto, ON > ThoughtStorm > Data Scientist/Analyst and Fraud Detection\n",
            "Toronto: Markham, ON > Scarsin > Data Scientist/Time Series\n",
            "Toronto: Toronto, ON > Capgemini > Data Scientist Senior Consultant - Toronto\n",
            "Toronto: Toronto, ON > Index Exchange > Senior Data Engineer\n",
            "Toronto: Toronto, ON > Tenstorrent > Software Engineer, Machine Learning Graph Compiler [Canada]...\n",
            "Toronto: Toronto, ON > RBC > Director, Data Science\n",
            "Toronto: Toronto, ON > Fathom > Software Engineer, Machine Learning\n",
            "Toronto: Toronto, ON > Quantiphi Inc. > Sr. Machine Learning Engineer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkZMme-TJJeD"
      },
      "source": [
        "# **Save to CSV**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toPhmj9bBn6e",
        "outputId": "1eeeccb9-1325-499b-ce7f-576344941fe8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "from datetime import datetime\n",
        "from google.colab import files\n",
        "\n",
        "# sending it to csvs to save the data\n",
        "now = datetime.now()\n",
        "dt_string = now.strftime(\"%y%m%d%H%M\")\n",
        "filename = \"Indeed_\" + dt_string + \".csv\"\n",
        "df.to_csv(filename , sep=',', encoding='utf-8')\n",
        "\n",
        "files.download(filename)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_cefb2cff-d7fa-4765-87b0-945a4a19abf0\", \"Indeed_2011140409.csv\", 39165)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}